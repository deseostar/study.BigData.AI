{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last updated: 2019-10-29 \n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.6.1\n",
      "\n",
      "numpy 1.17.2\n",
      "tensorflow 1.13.1\n",
      "matplotlib 3.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -u -d -v -p numpy,tensorflow,matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랭크: Tensor(\"Rank_6:0\", shape=(), dtype=int32) Tensor(\"Rank_7:0\", shape=(), dtype=int32) Tensor(\"Rank_8:0\", shape=(), dtype=int32)\n",
      "\n",
      "크기: () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "## t1, t2, t3 텐서를 정의합니다.\n",
    "t1 = tf.constant(np.pi)\n",
    "t2 = tf.constant([1, 2, 3, 4])\n",
    "t3 = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "## 랭크를 구합니다.\n",
    "r1 = tf.rank(t1)\n",
    "r2 = tf.rank(t2)\n",
    "r3 = tf.rank(t3)\n",
    "\n",
    "## 크기를 구합니다\n",
    "s1 = t1.get_shape()\n",
    "s2 = t2.get_shape()\n",
    "s3 = t3.get_shape()\n",
    "\n",
    "print('랭크:', r1, r2, r3)\n",
    "print()\n",
    "print('크기:', s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_9:0\", shape=(3, 4), dtype=float64)\n",
      "T1의 크기: (3, 4)\n",
      "T1의 크기: (3, 4)\n",
      "WARNING:tensorflow:From C:\\Users\\deseo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float64_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=float64_ref>\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1., 2., 3., 3.5],\n",
    "                [4., 5., 6., 6.5],\n",
    "                [7., 8., 9., 9.5]])\n",
    "T1 = tf.constant(arr)\n",
    "print(T1)\n",
    "s = T1.get_shape()\n",
    "print('T1의 크기:', s)\n",
    "print('T1의 크기:', T1.shape)\n",
    "T2 = tf.Variable(np.random.normal(size=s))\n",
    "print(T2)\n",
    "T3 = tf.Variable(np.random.normal(size=s[0]))\n",
    "print(T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  Tensor(\"add:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "b = tf.constant(2) \n",
    "c = tf.constant(3) \n",
    "\n",
    "z = 2*(a-b) + c\n",
    "\n",
    "print('2*(a-b)+c => ', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c =>  1\n"
     ]
    }
   ],
   "source": [
    "## 텐서플로 1.x 방식\n",
    "g = tf.Graph()\n",
    " \n",
    "## 그래프에 노드를 추가합니다.\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a')\n",
    "    b = tf.constant(2, name='b') \n",
    "    c = tf.constant(3, name='c') \n",
    "\n",
    "    z = 2*(a-b) + c\n",
    "    \n",
    "## 그래프를 실행합니다.\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c => ', sess.run(z))\n",
    "    \n",
    "#with tf.compat.v1.Session(graph=g) as sess:    # 텐서플로우 2.0 이상일때 사용\n",
    "#    print('2*(a-b)+c => ', sess.run(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'a' type=Const>,\n",
       " <tf.Operation 'b' type=Const>,\n",
       " <tf.Operation 'c' type=Const>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'mul/x' type=Const>,\n",
       " <tf.Operation 'mul' type=Mul>,\n",
       " <tf.Operation 'add' type=Add>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"a\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 1\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"b\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"c\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 3\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"sub\"\n",
       "  op: \"Sub\"\n",
       "  input: \"a\"\n",
       "  input: \"b\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul/x\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_INT32\n",
       "        tensor_shape {\n",
       "        }\n",
       "        int_val: 2\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"mul\"\n",
       "  op: \"Mul\"\n",
       "  input: \"mul/x\"\n",
       "  input: \"sub\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"add\"\n",
       "  op: \"Add\"\n",
       "  input: \"mul\"\n",
       "  input: \"c\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 27\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 직접적으로 사용하지 않고 학습 횟수에 따라 단순히 증가시킬 변수를 만듭니다.\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.))\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "# global_step로 넘겨준 변수를, 학습용 변수들을 최적화 할 때 마다 학습 횟수를 하나씩 증가시킵니다.\n",
    "train_op = optimizer.minimize(cost, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# 모델을 저장하고 불러오는 API를 초기화합니다.\n",
    "# global_variables 함수를 통해 앞서 정의하였던 변수들을 저장하거나 불러올 변수들로 설정합니다.\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model\\dnn.ckpt-2\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]]\n",
      "[[1 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#데이터 로드해보기\n",
    "df = pd.read_csv('C:/Users/deseo/AI ex Folder/introduction_to_ml_with_python-master/data/data.csv', header=None)\n",
    "\n",
    "x_data = df.iloc[:, 0:2].values\n",
    "y_data = df.iloc[:, 2:6].values\n",
    "\n",
    "print (x_data)\n",
    "print (y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9,  Cost: 0.998\n",
      "Step: 10,  Cost: 0.972\n"
     ]
    }
   ],
   "source": [
    "# 최적화 진행\n",
    "for step in range(2):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/dnn.ckpt-10'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화가 끝난 뒤, 변수를 저장합니다.\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서보드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 버전 텐서플로 2.0부터는 자체 내장,  이전 버전에서는 잘 안돌아감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서보드를 이용하기 위해 각종 변수들을 설정하고 저장하는 방법을 익혀봅니다.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope 으로 묶은 블럭은 텐서보드에서 한 레이어안에 표현해줍니다\n",
    "with tf.name_scope('layer1'):\n",
    "    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name='W1')\n",
    "    L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "with tf.name_scope('layer2'):\n",
    "    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name='W2')\n",
    "    L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "with tf.name_scope('output'):\n",
    "    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name='W3')\n",
    "    model = tf.matmul(L2, W3)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    cost = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "\n",
    "    # tf.summary.scalar 를 이용해 수집하고 싶은 값들을 지정할 수 있습니다.\n",
    "    tf.summary.scalar('cost', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state('./model')\n",
    "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 텐서보드에서 표시해주기 위한 텐서들을 수집합니다.\n",
    "merged = tf.summary.merge_all()\n",
    "# 저장할 그래프와 텐서값들을 저장할 디렉토리를 설정합니다.\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "# 이렇게 저장한 로그는, 학습 후 다음의 명령어를 이용해 웹서버를 실행시킨 뒤\n",
    "# tensorboard --logdir=./logs\n",
    "# = tensorboard --logdir=introduction_to_ml_with_python-master/logs\n",
    "# 다음 주소와 웹브라우저를 이용해 텐서보드에서 확인할 수 있습니다.\n",
    "# http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3,  Cost: 1.157\n",
      "Step: 4,  Cost: 1.104\n",
      "Step: 5,  Cost: 1.055\n",
      "Step: 6,  Cost: 1.010\n",
      "Step: 7,  Cost: 0.968\n",
      "Step: 8,  Cost: 0.931\n",
      "Step: 9,  Cost: 0.900\n",
      "Step: 10,  Cost: 0.876\n",
      "Step: 11,  Cost: 0.856\n",
      "Step: 12,  Cost: 0.840\n",
      "Step: 13,  Cost: 0.826\n",
      "Step: 14,  Cost: 0.814\n",
      "Step: 15,  Cost: 0.804\n",
      "Step: 16,  Cost: 0.794\n",
      "Step: 17,  Cost: 0.786\n",
      "Step: 18,  Cost: 0.779\n",
      "Step: 19,  Cost: 0.773\n",
      "Step: 20,  Cost: 0.768\n",
      "Step: 21,  Cost: 0.763\n",
      "Step: 22,  Cost: 0.759\n",
      "Step: 23,  Cost: 0.755\n",
      "Step: 24,  Cost: 0.752\n",
      "Step: 25,  Cost: 0.750\n",
      "Step: 26,  Cost: 0.748\n",
      "Step: 27,  Cost: 0.746\n",
      "Step: 28,  Cost: 0.744\n",
      "Step: 29,  Cost: 0.743\n",
      "Step: 30,  Cost: 0.742\n",
      "Step: 31,  Cost: 0.741\n",
      "Step: 32,  Cost: 0.740\n",
      "Step: 33,  Cost: 0.739\n",
      "Step: 34,  Cost: 0.739\n",
      "Step: 35,  Cost: 0.738\n",
      "Step: 36,  Cost: 0.738\n",
      "Step: 37,  Cost: 0.737\n",
      "Step: 38,  Cost: 0.737\n",
      "Step: 39,  Cost: 0.737\n",
      "Step: 40,  Cost: 0.736\n",
      "Step: 41,  Cost: 0.736\n",
      "Step: 42,  Cost: 0.736\n",
      "Step: 43,  Cost: 0.736\n",
      "Step: 44,  Cost: 0.735\n",
      "Step: 45,  Cost: 0.735\n",
      "Step: 46,  Cost: 0.735\n",
      "Step: 47,  Cost: 0.735\n",
      "Step: 48,  Cost: 0.735\n",
      "Step: 49,  Cost: 0.735\n",
      "Step: 50,  Cost: 0.735\n",
      "Step: 51,  Cost: 0.734\n",
      "Step: 52,  Cost: 0.734\n",
      "Step: 53,  Cost: 0.734\n",
      "Step: 54,  Cost: 0.734\n",
      "Step: 55,  Cost: 0.734\n",
      "Step: 56,  Cost: 0.734\n",
      "Step: 57,  Cost: 0.734\n",
      "Step: 58,  Cost: 0.734\n",
      "Step: 59,  Cost: 0.734\n",
      "Step: 60,  Cost: 0.734\n",
      "Step: 61,  Cost: 0.734\n",
      "Step: 62,  Cost: 0.734\n",
      "Step: 63,  Cost: 0.734\n",
      "Step: 64,  Cost: 0.734\n",
      "Step: 65,  Cost: 0.734\n",
      "Step: 66,  Cost: 0.734\n",
      "Step: 67,  Cost: 0.734\n",
      "Step: 68,  Cost: 0.734\n",
      "Step: 69,  Cost: 0.734\n",
      "Step: 70,  Cost: 0.734\n",
      "Step: 71,  Cost: 0.733\n",
      "Step: 72,  Cost: 0.733\n",
      "Step: 73,  Cost: 0.733\n",
      "Step: 74,  Cost: 0.733\n",
      "Step: 75,  Cost: 0.733\n",
      "Step: 76,  Cost: 0.733\n",
      "Step: 77,  Cost: 0.733\n",
      "Step: 78,  Cost: 0.733\n",
      "Step: 79,  Cost: 0.733\n",
      "Step: 80,  Cost: 0.733\n",
      "Step: 81,  Cost: 0.733\n",
      "Step: 82,  Cost: 0.733\n",
      "Step: 83,  Cost: 0.733\n",
      "Step: 84,  Cost: 0.733\n",
      "Step: 85,  Cost: 0.733\n",
      "Step: 86,  Cost: 0.733\n",
      "Step: 87,  Cost: 0.733\n",
      "Step: 88,  Cost: 0.733\n",
      "Step: 89,  Cost: 0.733\n",
      "Step: 90,  Cost: 0.733\n",
      "Step: 91,  Cost: 0.733\n",
      "Step: 92,  Cost: 0.733\n",
      "Step: 93,  Cost: 0.733\n",
      "Step: 94,  Cost: 0.733\n",
      "Step: 95,  Cost: 0.733\n",
      "Step: 96,  Cost: 0.733\n",
      "Step: 97,  Cost: 0.733\n",
      "Step: 98,  Cost: 0.733\n",
      "Step: 99,  Cost: 0.733\n",
      "Step: 100,  Cost: 0.733\n",
      "Step: 101,  Cost: 0.733\n",
      "Step: 102,  Cost: 0.733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./model/dnn.ckpt-102'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적화 진행\n",
    "for step in range(100):\n",
    "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "    print('Step: %d, ' % sess.run(global_step),\n",
    "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
    "\n",
    "    # 적절한 시점에 저장할 값들을 수집하고 저장합니다.\n",
    "    #summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})     #버전이 낮아서 위아래 두개 주석걸고 돌리니 됨\n",
    "    #writer.add_summary(summary, global_step=sess.run(global_step))   #버전이 낮아서 위아래 두개 주석걸고 돌리니 됨\n",
    "\n",
    "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값: [0 1 2 0 0 2]\n",
      "실제값: [0 1 2 0 0 2]\n",
      "정확도: 100.00\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 결과 확인\n",
    "# 0: 기타 1: 포유류, 2: 조류\n",
    "######\n",
    "prediction = tf.argmax(model, 1)\n",
    "target = tf.argmax(Y, 1)\n",
    "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
    "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
    "\n",
    "is_correct = tf.equal(prediction, target)\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=./logs\n",
    "# 다음 주소와 웹브라우저를 이용해 텐서보드에서 확인할 수 있습니다.\n",
    "# http://localhost:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 텐서플로우에 기본 내장된 mnist 모듈을 이용하여 데이터를 로드합니다.\n",
    "# 지정한 폴더에 MNIST 데이터가 없는 경우 자동으로 데이터를 다운로드합니다.\n",
    "# one_hot 옵션은 레이블을 동물 분류 예제에서 보았던 one_hot 방식의 데이터로 만들어줍니다.\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 이미지는 28x28 픽셀로 이루어져 있고, 이를 784개의 특성값으로 정합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 결과는 0~9 의 10 가지 분류를 가집니다.\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
    "#   -> 10 (결과값 0~9 분류)\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.399\n",
      "Epoch: 0002 Avg. cost = 0.141\n",
      "Epoch: 0003 Avg. cost = 0.093\n",
      "Epoch: 0004 Avg. cost = 0.068\n",
      "Epoch: 0005 Avg. cost = 0.052\n",
      "Epoch: 0006 Avg. cost = 0.038\n",
      "Epoch: 0007 Avg. cost = 0.030\n",
      "Epoch: 0008 Avg. cost = 0.025\n",
      "Epoch: 0009 Avg. cost = 0.021\n",
      "Epoch: 0010 Avg. cost = 0.015\n",
      "Epoch: 0011 Avg. cost = 0.016\n",
      "Epoch: 0012 Avg. cost = 0.013\n",
      "Epoch: 0013 Avg. cost = 0.012\n",
      "Epoch: 0014 Avg. cost = 0.011\n",
      "Epoch: 0015 Avg. cost = 0.011\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        # 텐서플로우의 mnist 모델의 next_batch 함수를 이용해\n",
    "        # 지정한 크기만큼 학습할 데이터를 가져옵니다.\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9776\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images,\n",
    "                                   Y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-93-c77a009bb793>:3: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우에 내장된 함수를 이용하여 dropout 을 적용합니다.\n",
    "# 함수에 적용할 레이어와 확률만 넣어주면 됩니다. 겁나 매직!!\n",
    "L1 = tf.nn.dropout(L1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L2, W3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.426\n",
      "Epoch: 0002 Avg. cost = 0.161\n",
      "Epoch: 0003 Avg. cost = 0.110\n",
      "Epoch: 0004 Avg. cost = 0.086\n",
      "Epoch: 0005 Avg. cost = 0.073\n",
      "Epoch: 0006 Avg. cost = 0.059\n",
      "Epoch: 0007 Avg. cost = 0.053\n",
      "Epoch: 0008 Avg. cost = 0.046\n",
      "Epoch: 0009 Avg. cost = 0.042\n",
      "Epoch: 0010 Avg. cost = 0.037\n",
      "Epoch: 0011 Avg. cost = 0.032\n",
      "Epoch: 0012 Avg. cost = 0.028\n",
      "Epoch: 0013 Avg. cost = 0.030\n",
      "Epoch: 0014 Avg. cost = 0.027\n",
      "Epoch: 0015 Avg. cost = 0.025\n",
      "Epoch: 0016 Avg. cost = 0.024\n",
      "Epoch: 0017 Avg. cost = 0.022\n",
      "Epoch: 0018 Avg. cost = 0.022\n",
      "Epoch: 0019 Avg. cost = 0.020\n",
      "Epoch: 0020 Avg. cost = 0.019\n",
      "Epoch: 0021 Avg. cost = 0.020\n",
      "Epoch: 0022 Avg. cost = 0.020\n",
      "Epoch: 0023 Avg. cost = 0.016\n",
      "Epoch: 0024 Avg. cost = 0.018\n",
      "Epoch: 0025 Avg. cost = 0.017\n",
      "Epoch: 0026 Avg. cost = 0.017\n",
      "Epoch: 0027 Avg. cost = 0.017\n",
      "Epoch: 0028 Avg. cost = 0.018\n",
      "Epoch: 0029 Avg. cost = 0.017\n",
      "Epoch: 0030 Avg. cost = 0.014\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.8})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9809\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images,\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = sess.run(model,\n",
    "                  feed_dict={X: mnist.test.images,\n",
    "                             Y: mnist.test.labels,\n",
    "                             keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
    "                   cmap=plt.cm.gray_r)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 이미지 처리 분야에서 가장 유명한 신경망 모델인 CNN 을 이용하여 더 높은 인식률을 만들어봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 구성\n",
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 모델에서는 입력 값을 28x28 하나의 차원으로 구성하였으나,\n",
    "# CNN 모델을 사용하기 위해 2차원 평면과 특성치의 형태를 갖는 구조로 만듭니다.\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각의 변수와 레이어는 다음과 같은 형태로 구성됩니다.\n",
    "# W1 [3 3 1 32] -> [3 3]: 커널 크기, 1: 입력값 X 의 특성수, 32: 필터 갯수\n",
    "# L1 Conv shape=(?, 28, 28, 32)\n",
    "#    Pool     ->(?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# tf.nn.conv2d 를 이용해 한칸씩 움직이는 컨볼루션 레이어를 쉽게 만들 수 있습니다.\n",
    "# padding='SAME' 은 커널 슬라이딩시 최외곽에서 한칸 밖으로 더 움직이는 옵션\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "# Pooling 역시 tf.nn.max_pool 을 이용하여 쉽게 구성할 수 있습니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Conv shape=(?, 14, 14, 64)\n",
    "#    Pool     ->(?, 7, 7, 64)\n",
    "# W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L2 = tf.nn.dropout(L2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC 레이어: 입력값 7x7x64 -> 출력값 256\n",
    "# Full connect를 위해 직전의 Pool 사이즈인 (?, 7, 7, 64) 를 참고하여 차원을 줄여줍니다.\n",
    "#    Reshape  ->(?, 256)\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "#optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)     #주석건 위 대신에 이걸로 하니까 정확도 약간 더 오름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.920\n",
      "Epoch: 0002 Avg. cost = 0.103\n",
      "Epoch: 0003 Avg. cost = 0.066\n",
      "Epoch: 0004 Avg. cost = 0.048\n",
      "Epoch: 0005 Avg. cost = 0.041\n",
      "Epoch: 0006 Avg. cost = 0.035\n",
      "Epoch: 0007 Avg. cost = 0.029\n",
      "Epoch: 0008 Avg. cost = 0.025\n",
      "Epoch: 0009 Avg. cost = 0.023\n",
      "Epoch: 0010 Avg. cost = 0.021\n",
      "Epoch: 0011 Avg. cost = 0.018\n",
      "Epoch: 0012 Avg. cost = 0.016\n",
      "Epoch: 0013 Avg. cost = 0.016\n",
      "Epoch: 0014 Avg. cost = 0.015\n",
      "Epoch: 0015 Avg. cost = 0.012\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.7})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9916\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
